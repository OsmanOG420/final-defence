{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1at5PBoqSIi2lFPRlxD_CGZH5clUhIzhH","authorship_tag":"ABX9TyOMNT3ABePodiEk7UQquFq9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q__ImxmSG2ro","executionInfo":{"status":"ok","timestamp":1734097383861,"user_tz":-360,"elapsed":19362,"user":{"displayName":"Razib Khan","userId":"07914798416388560118"}},"outputId":"7343e3ea-335f-4cac-c39f-4ac5a6f0a9a9"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RLviI_XcGep5"},"outputs":[],"source":["# import os\n","# import numpy as np\n","# from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, save_img\n","# from PIL import Image  # For compression\n","\n","# # Define the root directory for your dataset and the output directory for augmented images\n","# root_folder = '/content/drive/MyDrive/mashroom_task/dataset'  # Path to your root folder\n","# output_folder = '/content/drive/MyDrive/mashroom_task/aug-data'  # Path to save augmented images\n","\n","# # Create the output folder structure (same as the original)\n","# os.makedirs(output_folder, exist_ok=True)\n","# classes = os.listdir(root_folder)  # List of class folders\n","\n","# # Loop through each class\n","# for cls in classes:\n","#     os.makedirs(os.path.join(output_folder, cls), exist_ok=True)  # Create class folder in output directory\n","\n","# # Define the ImageDataGenerator for data augmentation\n","# datagen = ImageDataGenerator(\n","#     rotation_range=40,\n","#     width_shift_range=0.2,\n","#     height_shift_range=0.2,\n","#     shear_range=0.2,\n","#     zoom_range=0.2,\n","#     horizontal_flip=True,\n","#     fill_mode='nearest'\n","# )\n","\n","# # Iterate through each class and augment images\n","# for cls in classes:\n","#     cls_input_path = os.path.join(root_folder, cls)  # Path to current class folder\n","#     cls_output_path = os.path.join(output_folder, cls)  # Path to save augmented images for this class\n","\n","#     images = os.listdir(cls_input_path)  # List of images in the current class folder\n","\n","#     # Loop through each image in the class\n","#     for img_name in images:\n","#         img_path = os.path.join(cls_input_path, img_name)\n","\n","#         try:\n","#             # Load and preprocess the image\n","#             img = load_img(img_path)  # Load image\n","#             img_array = img_to_array(img)  # Convert image to array\n","#             img_array = np.expand_dims(img_array, axis=0)  # Expand dimensions for batch processing\n","\n","#             # Save the original image to the output folder\n","#             original_img_path = os.path.join(cls_output_path, img_name)\n","#             img.save(original_img_path, \"JPEG\", quality=85)  # Compress original image\n","\n","#             # Generate and save augmented images\n","#             for i, batch in enumerate(datagen.flow(img_array, batch_size=1, save_to_dir=None)):\n","#                 augmented_img_name = f\"{os.path.splitext(img_name)[0]}_aug_{i + 1}.jpg\"\n","#                 augmented_img_path = os.path.join(cls_output_path, augmented_img_name)\n","\n","#                 # Save the augmented image with compression\n","#                 augmented_img = Image.fromarray(batch[0].astype('uint8'))\n","#                 augmented_img.save(augmented_img_path, \"JPEG\", quality=85)  # Save as JPG with compression\n","\n","#                 if i >= 1:  # Generate only 2 augmented images per input\n","#                     break\n","#         except Exception as e:\n","#             print(f\"Error processing {img_name} in {cls}: {e}\")\n","\n","# print(\"Data augmentation completed!\")\n"]},{"cell_type":"code","source":["import os\n","import shutil\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from sklearn.model_selection import train_test_split\n","\n","# Define the dataset directory and output directories\n","data_dir = '/content/drive/MyDrive/mashroom_task/dataset'\n","output_dir = '/content/drive/MyDrive/mashroom_task/split_dataset'\n","classes = os.listdir(data_dir)  # Assuming each folder represents a class\n","\n","# Create output directories for train, val, and test splits\n","split_ratios = {'train': 0.6, 'val': 0.2, 'test': 0.2}\n","for split in split_ratios:\n","    for cls in classes:\n","        os.makedirs(os.path.join(output_dir, split, cls), exist_ok=True)\n","\n","# Split data into train, val, and test\n","for cls in classes:\n","    cls_path = os.path.join(data_dir, cls)\n","    images = os.listdir(cls_path)\n","    train_files, temp_files = train_test_split(images, test_size=1 - split_ratios['train'], random_state=42)\n","    val_files, test_files = train_test_split(temp_files, test_size=split_ratios['test'] / (split_ratios['val'] + split_ratios['test']), random_state=42)\n","\n","    for file in train_files:\n","        shutil.copy(os.path.join(cls_path, file), os.path.join(output_dir, 'train', cls))\n","    for file in val_files:\n","        shutil.copy(os.path.join(cls_path, file), os.path.join(output_dir, 'val', cls))\n","    for file in test_files:\n","        shutil.copy(os.path.join(cls_path, file), os.path.join(output_dir, 'test', cls))\n","\n","# Define data generators\n","train_datagen = ImageDataGenerator(\n","    rescale=1.0/255,\n","    rotation_range=40,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")\n","\n","validation_datagen = ImageDataGenerator(\n","    rescale=1.0/255\n",")\n","\n","# Define data directories and parameters\n","target_size = (224, 224)\n","batch_size = 32\n","\n","# Create data flows for train, validation, and test datasets\n","train = train_datagen.flow_from_directory(\n","    os.path.join(output_dir, 'train'),\n","    target_size=target_size,\n","    batch_size=batch_size,\n","    class_mode='categorical'\n",")\n","\n","validation = validation_datagen.flow_from_directory(\n","    os.path.join(output_dir, 'val'),\n","    target_size=target_size,\n","    batch_size=batch_size,\n","    class_mode='categorical'\n",")\n","\n","test = validation_datagen.flow_from_directory(\n","    os.path.join(output_dir, 'test'),\n","    target_size=target_size,\n","    batch_size=batch_size,\n","    shuffle=False,\n","    class_mode='categorical'\n",")\n","\n","# Verify class indices\n","print(\"Class indices:\", train.class_indices)\n"],"metadata":{"id":"QzOKvbBoG1Wc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734097768268,"user_tz":-360,"elapsed":327781,"user":{"displayName":"Razib Khan","userId":"07914798416388560118"}},"outputId":"968c66de-7264-4656-bb46-2fdde2cfd488"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 3064 images belonging to 6 classes.\n","Found 1021 images belonging to 6 classes.\n","Found 1021 images belonging to 6 classes.\n","Class indices: {'Agaricus': 0, 'Blue_Oyster_Mushroom': 1, 'Oyster_Mushroom': 2, 'Phoenix_Oyster_Mushrooms': 3, 'Pink_Oyster_Mushroom': 4, 'poisonous_mushroom_sporocarp': 5}\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"hO-4w5BSOCse"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"RnPP5la4OCvM"},"execution_count":null,"outputs":[]}]}